\documentclass[12pt]{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[utf8]{inputenc}

\usepackage{hyperref}
\usepackage{xcolor}

\hypersetup{
  colorlinks=true,
  citecolor=blue,
  linkcolor=red,
  urlcolor=magenta,
  }
  % citebordercolor=false}

\usepackage{float}
\usepackage{url}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{xurl}
\usepackage{lineno}
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage[linesnumbered, ruled]{algorithm2e}

\usepackage{ulem}
\newcommand{\stkout}[1]{\ifmmode\text{\sout{\ensuremath{#1}}}\else\sout{#1}\fi}

\usepackage{multirow}
\usepackage{longtable}
\setlength\LTleft{0pt}
\usepackage{tabularx}

\usepackage{graphicx}
% \setlength\LTleft{0pt}


% \bibliographystyle{unsrt}
\bibliographystyle{agu}
% \bibliographystyle{plainnat}

\newcommand\prob{\mathbb{P}}


%
\usepackage{epsfig}
\usepackage[linesnumbered, ruled]{algorithm2e}

\usepackage{natbib}
\usepackage{color}

%
%
%

\usepackage{multirow}
\usepackage{longtable}
\setlength\LTleft{0pt}
\usepackage{tabularx}
%
\clearpage{}%


\newcommand{\xh}[1]{\textcolor{orange}{\textbf{(xh:)} #1}}

\newcommand{\aj}[1]{\textcolor{magenta}{\textbf{(aj:)} #1}}

%
\newcommand{\resp}[1]{\textcolor{red}{\textbf{Response: } #1}}
\newcommand{\respc}[1]{\textcolor{red}{#1}}

\newcommand\Myperm[2][^n]{\prescript{#1\mkern-2.5mu}{}P_{#2}}
\newcommand\Mycomb[2][^n]{\prescript{#1\mkern-0.5mu}{}C_{#2}}
%
\renewcommand{\[}{\left[}
\renewcommand{\]}{\right]}
\renewcommand{\(}{\left(}
\renewcommand{\)}{\right)}

%
\newcommand{\dd}[2]{\frac{d #1}{d #2}}
\newcommand{\ddt}[1]{\frac{d #1}{d t}}
\newcommand{\ddd}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\dddt}[1]{\frac{d^2 #1}{d t^2}}
\newcommand{\pp}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\ppp}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\pppp}[2]{\frac{\partial^3 #1}{\partial #2^3}}
\newcommand{\ppppp}[2]{\frac{\partial^4 #1}{\partial #2^4}}

\newcommand{\adj}[1]{#1^{*}}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\divergence}[1]{\nabla \cdot #1}
\newcommand{\enorm}[1]{\vvvert #1 \vvvert}
\newcommand{\grad}[1]{\nabla #1}
\newcommand{\laplace}[1]{\nabla^2 #1}
\newcommand{\norm}[2]{\left\|\, #1 \,\right\|_{#2}}
\newcommand{\order}[1]{\mathcal{O}\(#1\)}
\newcommand{\supp}{\mathop{\mathrm{supp}}}
\newcommand{\vvvert}{|\kern-1pt|\kern-1pt|}

\newcommand{\eq}[1]{\mathop{\,{\buildrel #1 \over =}\,}}
\newcommand{\ap}[1]{\mathop{\,{\buildrel #1 \over \approx}\,}}

%

%
\newcommand{\hg}{\hat{g}}
\newcommand{\hh}{\hat{h}}
\newcommand{\hi}{\hat{i}}
\newcommand{\hj}{\hat{j}}
\newcommand{\hk}{\hat{k}}
\newcommand{\hm}{\hat{m}}
\newcommand{\hn}{\hat{n}}
\newcommand{\hs}{\hat{s}}
\newcommand{\hu}{\hat{u}}
\newcommand{\hv}{\hat{v}}
\newcommand{\hx}{\hat{x}}

\newcommand{\hA}{\hat{A}}
\newcommand{\hC}{\hat{C}}
\newcommand{\hI}{\hat{I}}
\newcommand{\hJ}{\hat{J}}
\newcommand{\hN}{\hat{N}}
\newcommand{\hT}{\hat{T}}
\newcommand{\hU}{\hat{U}}

\newcommand{\hbf}{\boldsymbol{\hat{f}}}
\newcommand{\hbg}{\boldsymbol{\hat{g}}}
\newcommand{\hsig}{\hat{\sigma}}

%
\newcommand{\barg}{\bar{g}}
\newcommand{\barh}{\bar{h}}
\newcommand{\barm}{\bar{m}}
\newcommand{\barv}{\bar{v}}
\newcommand{\barw}{\bar{w}}
\newcommand{\barx}{\bar{x}}
\newcommand{\bary}{\bar{y}}

\newcommand{\barB}{\bar{B}}
\newcommand{\barC}{\bar{C}}
\newcommand{\barH}{\bar{H}}
\newcommand{\barJ}{\bar{J}}
\newcommand{\barN}{\bar{N}}
\newcommand{\barR}{\bar{R}}

\newcommand{\barmu}{\bar{\mu}}

%
\newcommand{\tf}{\tilde{f}}
\newcommand{\thh}{\tilde{h}}

\newcommand{\tA}{\tilde{A}}
\newcommand{\tg}{\tilde{g}}
\newcommand{\tH}{\tilde{H}}
\newcommand{\tJ}{\tilde{J}}
\newcommand{\tQ}{\tilde{Q}}
\newcommand{\tT}{\tilde{T}}

\newcommand{\tmu}{\tilde{\mu}}
\newcommand{\ttheta}{\tilde{\theta}}
\newcommand{\txi}{\tilde{\xi}}

\newcommand{\tTheta}{\tilde{\Theta}}
\newcommand{\tXi}{\tilde{\Xi}}

%
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\sbf}[1]{\boldsymbol{#1}}

\newcommand{\bb}{\textbf{b}}
\newcommand{\bd}{\textbf{d}}
\newcommand{\bee}{\textbf{e}}
\newcommand{\bff}{\textbf{f}}
\newcommand{\bh}{\textbf{h}}
\newcommand{\bg}{\textbf{g}}
\newcommand{\bk}{\textbf{k}}
\newcommand{\bii}{\textbf{i}}
\newcommand{\bj}{\textbf{j}}
\newcommand{\bl}{\textbf{l}}
\newcommand{\bn}{\textbf{n}}
\newcommand{\bp}{\textbf{p}}
\newcommand{\br}{\textbf{r}}
\newcommand{\bs}{\textbf{s}}
\newcommand{\bt}{\textbf{t}}
\newcommand{\bu}{\textbf{u}}
\newcommand{\bv}{\textbf{v}}
\newcommand{\bw}{\textbf{w}}
\newcommand{\bx}{\textbf{x}}
\newcommand{\by}{\textbf{y}}

\newcommand{\bA}{\mathbf{A}}
\newcommand{\bC}{\mathbf{C}}
\newcommand{\bE}{\mathbf{E}}
\newcommand{\bF}{\mathbf{F}}
\newcommand{\bG}{\mathbf{G}}
\newcommand{\bI}{\mathbf{I}}
\newcommand{\bK}{\mathbf{K}}
\newcommand{\bN}{\mathbf{N}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bR}{\mathbf{R}}
\newcommand{\bT}{\mathbf{T}}
\newcommand{\bU}{\mathbf{U}}
\newcommand{\bV}{\mathbf{V}}
\newcommand{\bY}{\mathbf{Y}}

\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bepsilon}{\boldsymbol{\epsilon}}
\newcommand{\bhsig}{\boldsymbol{\hsig}}
\newcommand{\bpsi}{\boldsymbol{\psi}}
\newcommand{\bsig}{\boldsymbol{\sigma}}
\newcommand{\btau}{\boldsymbol{\tau}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\bxi}{\boldsymbol{\xi}}

\newcommand{\bDelta}{\boldsymbol{\Delta}}
\newcommand{\bTheta}{\boldsymbol{\Theta}}
\newcommand{\bXi}{\boldsymbol{\Xi}}
\newcommand{\bOmega}{\boldsymbol{\Omega}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}

%
\newcommand{\EE}{\mathbb{E}}
\newcommand{\II}{\mathbb{I}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\RR}{\mathbb{R}}

%
\newcommand{\vt}{\vec{t}}
\newcommand{\vu}{\vec{u}}
\newcommand{\vv}{\vec{v}}
\newcommand{\vx}{\vec{x}}

\newcommand{\vV}{\vec{V}}

\newcommand{\vo}{\vec{\omega}}

%
\newcommand{\dotk}{\dot{k}}
\newcommand{\dotm}{\dot{m}}
\newcommand{\dotx}{\dot{x}}

\newcommand{\dotomega}{\dot{\omega}}

%
\newcommand{\CA}{\mathcal{A}}
\newcommand{\CB}{\mathcal{B}}
\newcommand{\CD}{\mathcal{D}}
\newcommand{\CE}{\mathcal{E}}
\newcommand{\CF}{\mathcal{F}}
\newcommand{\CG}{\mathcal{G}}
\newcommand{\CH}{\mathcal{H}}
\newcommand{\CJ}{\mathcal{J}}
\newcommand{\CK}{\mathcal{K}}
\newcommand{\CL}{\mathcal{L}}
\newcommand{\CM}{\mathcal{M}}
\newcommand{\CN}{\mathcal{N}}
\newcommand{\CR}{\mathcal{R}}
\newcommand{\CS}{\mathcal{S}}
\newcommand{\CT}{\mathcal{T}}
\newcommand{\CU}{\mathcal{U}}
\newcommand{\CV}{\mathcal{V}}
\newcommand{\CW}{\mathcal{W}}
\newcommand{\CX}{\mathcal{X}}
\newcommand{\CY}{\mathcal{Y}}

\newcommand{\CbarJ}{\bar{\mathcal{J}}}
\newcommand{\CbarL}{\bar{\mathcal{L}}}
\newcommand{\CbarR}{\bar{\mathcal{R}}}

%
\newcommand{\du}{\delta{u}}

\newcommand{\dbeta}{\delta{\beta}}
\newcommand{\dxi}{\delta{\xi}}
\newcommand{\deta}{\delta{\eta}}
\newcommand{\drho}{\delta{\rho}}
\newcommand{\dtau}{\delta{\tau}}

\newcommand{\dbu}{\delta{\boldsymbol{u}}}
\newcommand{\dbp}{\delta{\boldsymbol{p}}}
\newcommand{\dbx}{\delta{\boldsymbol{x}}}

\newcommand{\Dx}{\Delta{x}}
\newcommand{\Dy}{\Delta{y}}
\newcommand{\Dt}{\Delta{t}}

%
\newcommand{\myblue}[1]{{\color[rgb]{0,0,0.65} #1}}
\newcommand{\mygreen}[1]{{\color[rgb]{0,.65,0} #1}}
\newcommand{\mywhite}[1]{{\color[rgb]{1.0,1.0,1.0} #1}}
\newcommand{\myred}[1]{{\color[rgb]{0.65,0.0,0.0} #1}}
\newcommand{\myblack}[1]{{\color[rgb]{0.0,0.0,0.0} #1}}
\newcommand{\mygrey}[1]{{\color[rgb]{0.6,0.6,0.6} #1}}

%
% \newcommand{\coo}{CO$_2$}
% \newcommand{\hho}{H$_2$O}
% \newcommand{\oo}{O$_2$}
% \newcommand{\nn}{N$_2$}
% \newcommand{\mwe}{MW$_e$}
% \newcommand{\nox}{NO$_{\textrm{x}}$}
% \newcommand{\cooe}{CO$_{2e}$}
% \newcommand{\nno}{N$_2$O}
% \newcommand{\noo}{NO$_2$ }
% \newcommand{\chhhh}{CH$_4$ }
% \newcommand{\hhoo}{H$_2$O$_2$}
% \newcommand{\hhoor}{H$_2$-O$_2$}
%
\newcommand{\degs}{^\circ}
% \newcommand{\Jpkmol}{\frac{J}{kmol}}
% \newcommand{\JpkmolK}{\frac{J}{kmol K}}
% \newcommand{\Jpkg}{\frac{J}{kg}}
% \newcommand{\JpkgK}{\frac{J}{kg K}}

\newcommand{\ra}{\rightarrow}
\newcommand{\Ra}{\Rightarrow}
\newcommand{\LRa}{\Longrightarrow}
\newcommand{\lra}{\longrightarrow}

\newcommand{\pe}{\,{\scriptstyle +}\!\!=}
\newcommand{\me}{\,{\scriptstyle -}\!\!=}
\newcommand{\Var}{\textrm{Var}}
\newcommand{\Cov}{\textrm{Cov}}
\newcommand{\diag}{\textrm{diag}}

\newcommand{\etal}{\textit{et al.}}

% \newcommand{\dkl}

\def\sgn{\mathop{\rm sgn}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\DKL}{D_{\mathrm{KL}}}

\newcommand{\iid}{\stackrel{\textrm{iid}}{\sim}}
\newcommand{\ti}[1]{\textbf{Title: }\textit{{#1}}}

\newcommand{\alf}{Alfv\'{e}n}
\newcommand{\Rs}{R$_{\odot}$}


\usepackage{algorithmic}
% \usepackage{algpseudocode}



\linenumbers

\title{Scalable Stein Variational Gradient Descent via Adaptive Spectral Delta Kernel Learning and Multifidelity Likelihoods}
% \author{Aniket Jivani, Thomas Coons}
\date{\today}

\begin{document}

\maketitle
\section*{Abstract}
Stein's method was originally developed to approximate certain classes of computations in terms of properties of a family of probability-characterising linear operators. 
These operators have since found application in a number of problems in hypothesis testing, information theory, optimal transport and inference. 
A simple method for performing Bayesian Inference, called Stein Variational Gradient Descent (SVGD), relies on gradient-based updates using kernelized Stein discrepancy to deterministically transport particles and approximate a posterior distribution of model parameters in the process. 
However this method frequently breaks down in higher dimensions without the use of projection-based approximations, and often relies on other heuristics to characterize and compute the kernel evaluations.
In this work, we begin by characterizing the exact trade-offs of Stein's method for different algorithmic choices. 
We then introduce a multifidelity version of SVGD that brings down the overall cost of particle position updates by leveraging computationally inexpensive lower-fidelity models for the likelihood.
We also propose some extensions to the original method that bridge the gap to the broader literature on graph-based techniques, flow-based methods and kernel machines. 
The connections uncovered in this process can facilitate the use of Stein's method in a much broader setting.



\section{Introduction}



\section{Related Work}

\begin{enumerate}
    \item Projected SVGD \cite{chen_projected_2020}

    \item Spectral Delta Kernels \cite{lazaro-gredilla_sparse_2010}

    \item Active Subspace based reduction for BNNs \cite{jantre_learning_2023}

    \item Continuous Normalizing Flows \cite{grathwohl_ffjord_2018}

    \item Kernelized Normalizing Flows \cite{english_kernelised_2024}

    \item SVGD as Gradient Flow \cite{liu_stein_2017}

    \item Stein breakdown in high dimensions \cite{ba_towards_2019}

    \item Stein's Method for High Dimensions \cite{chang_kernel_2020} - while the paper is almost unreadable, the authors try to use ideas from score matching such as Anneal-SGLD on the vanilla SVGD procedure and find that the kernel choice is inadequate because the bandwidth is not changing with respect to the noise level. Their proposed kernel includes an autoencoder for dimensionality reduction and conditions the hyperparameters on $\sigma$.

    \item Multilevel SVGD \cite{alsup_multilevel_2022}


    \item Alternate forms of the Stein Operator based on divergence \textcolor{red}{ours!}
\end{enumerate}

\section{Methodology}

\subsection{Bifidelity Model / Surrogate SVGD}

Consider high-fidelity and low-fidelity models with their corresponding log-likelihoods:

\begin{align}
 L_0 &= \log p(y_0 | x, \theta) = \sum_{i=1}^{N} \log p(y_0^i | x, \theta) \\
 L_1 &= \log p(y_1 | x, \theta) = \sum_{i=1}^{N} \log p(y_1^i | x, \theta)
\end{align}


Then assuming an additive correction, a simple Stein update for the parameters $\theta_i$ would become:

\begin{equation}
    \theta_i \leftarrow \theta_i + \epsilon \phi^{\ast}(\theta)
\end{equation}

where 

\begin{equation}
    \phi^{\ast}(\theta) = \frac{1}{M}\sum_{j=1}^{M}[k(\theta_j, \theta) \grad_{\theta_j}[(L_{1}(\theta_j) + L_{\Delta}(\theta_j) + \log p(\theta)] + \grad_{\theta_j} k(\theta_j, \theta)]
\end{equation}

While this framework does on the surface, construct an update equation based on multiple models, it comes with its fair share of drawbacks: for one, it requires us to propose an adequate estimator for $L_{\Delta}$, followed by a design for pilot samples to correlate the two models and a formal accounting of the bias introduced by this correction. 
A simpler strategy is to assign model fidelities to individual particles, and modify the update algorithm suitably to target cost savings via strategic querying of high-fidelity model updates. While not quite used for Bayesian inference, similar ideas have found traction in the field of rare event estimation \cite{dhulipala_bayesian_2022}, where the objective is to use the uncertainty from low-fidelity model outputs as an indicator of proximity of particles to the failure boundary. Following this, the limit state function can be computed through the higher-fidelity model and sample the boundary efficiently.

\subsection{Generalized Multifidelity SVGD}

We treat the Stein update functions as scalar QoIs. Then the high-fidelity particle positions i.e. those generated using the likelihood of the high-fidelity model are given by:

\begin{equation*}
    \theta^{(0)}_i \leftarrow \theta^{(0)}_i + \epsilon \phi^{\ast}(\theta^{(0)})
\end{equation*}

And similarly, for lower-fidelity models indexed from $1$ to $m$, we can compute the particle positions as:

\begin{equation*}
    \theta^{(l)}_i \leftarrow \theta^{(l)}_i + \epsilon \phi^{\ast}(\theta^{(l)}), \quad l=1, \cdots, m
\end{equation*}

where

\begin{equation}
    \phi^{\ast}(\theta^{(0)}) = \frac{1}{M}\sum_{j=1}^{M}[k(\theta_j, \theta^{(0)}) \grad_{\theta_j}[L_{0} + \log p(\theta_j)] + \grad_{\theta_j} k(\theta_j, \theta^{(0)})]
\end{equation}

\begin{equation}
    \phi^{\ast}(\theta^{(l)}) = \frac{1}{M}\sum_{j=1}^{M}[k(\theta_j, \theta^{(l)}) \grad_{\theta_j}[L_{l} + \log p(\theta_j)] + \grad_{\theta_j} k(\theta_j, \theta^{(l)})]
\end{equation}

While the $M$ particles are allocated to different models as $M_0, M_1, \cdots, M_m$, the above updates still use all the particles to compute the map at each iteration - this introduces interactions between the multifidelity particles in both terms: the first term driving the particles to regions of high-probability and the second term accounting for the repulsive force that prevents particle collapse into local modes. 

The above formulation continues to allow flexibility and raises additional open questions regarding the following aspects:

\begin{enumerate}
    \item The choice of the kernel function for individual model fidelities

    \item The prescription of particles to different model fidelities and how it changes as we step through the method.

    \item The number and allocation of particles used in computations of the kernel function i.e. neighbourhood selection for particles.

    \item The frequency of updates to particles of different fidelities.

    \item The stopping criterion that assesses convergence to the target distribution.
\end{enumerate}

In the following sections, we will examine the impact of each of the above choices on the proposed method.

\subsection{Particle assignment to various fidelities}

\emph{Method 1: Randomized Assignment}


\noindent \emph{Method 2: Resource allocation using model correlations}

\subsection{Graph Network Based Propagation}
Deep learning methods that model arbitrary relational structures between elements, such as graph networks (GNs), are surveyed in \cite{battaglia_relational_2018}. 

GNs model a domain by decomposing it into a graphical representation $\CG=\{\CV, \CE\}$ - nodes $\CV$ that represent individual features and edges $\CE$ that describe directed or undirected interactions between nodes. 
The learning proceeds by first defining a neighbourhood for individual nodes. This is followed by a message-passing block that updates node features based on aggregating interactions with all or a subset of its possible neighbours. Chaining several such blocks with intermediate nonlinear activations results in a GN which accepts an arbitrarily sized graph as input and returns either a transformed graph or some global property of the graph as the output. 

Superficially translating the graphical representation to a particle-based updates / normalizing flow setup suggests the propagation of augmented node features $[x, \log p(x)]$ where both the particle positions $x$ and their log-likelihoods $\log p(x)$ are updated as they pass through the message-passing blocks. Two key advantages offered by graph-based methods are their inherent invariance to permutations (unlike MLPs) and their ability to operate on graphs of arbitrary sizes without modifications to the architecture. 
This feature translates to so-called `discretization invariance' in expressive methods for learning PDEs such as neural operators \citep{Li2020} which exhibit good generalization properties even when trained on low-resolution data. GNs have been successfully used to simulate complex physics with long rollout times, e.g. \cite{sanchez-gonzalez_learning_2020}.

Without additional constraints however, a GN is not directly compatible with the workflow of particle-based methods for inference, where the key goal is to constrain the transport of individual particles by minimizing a particular discrepancy function that characterizes the quality of the posterior approximation. 
It is also unclear if the discretization-invariance property grants any advantages in better representation of the posterior density in low-data settings. 
However, the advances in scaling GNs to very large graphs with millions of nodes suggest opportunities to influence the development of scalable particle methods for inference and offer a more flexible workflow. 
We begin with a brief overview of our proposed changes below:



\section{Results}

\subsection{Posterior Approximation in High Dimensions}


\subsection{Density Estimation}
We consider the quality of density estimation for varying numbers of particles. 
We also consider the case where the original inference is performed on a small set of $N$ particles, but density estimation may be desired with additional particles at test time. 
Then we need the ability to perform rapid approximation of positions for $K$ new particles introduced at test time. 
This would require $\Mycomb[(N+K)]{2} - \Mycomb[N]{2} = \frac{1}{2}(K^2 + 2NK - K)$ additional distance calculations and $K$ potentially expensive likelihood computations followed by density estimation in the naive setting. 
By contrast, a trained simulator that is `discretization invariant' in some sense can update the particles and provide better density estimates in a semi-supervised manner.

\subsection{}

\section{Conclusions and Extensions}



\bibliography{local,references}


\section*{Appendix}

\end{document}

